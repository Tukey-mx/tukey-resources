# Deep Learning

---

âœ… -> AÃ±adido  
âœï¸ -> En progreso

---

## Ãndice

| Tema | Estado |
|------|--------|
| [Neurona de McCulloch-Pitts](#neurona-de-mcculloch-pitts) | âœ… |
| [PerceptrÃ³n](#perceptrÃ³n) | âœ… |
| [Redes Feedforward (MLP)](#redes-feedforward-mlp) | âœ… |
| [Backpropagation](#backpropagation) | âœ… |
| [Funciones de activaciÃ³n](#funciones-de-activaciÃ³n) | âœ… |
| [Redes Radiales (RBF)](#redes-radiales-rbf) | âœ… |
| [Redes de Hopfield](#redes-de-hopfield) | âœ… |
| [RegularizaciÃ³n y optimizaciÃ³n](#regularizaciÃ³n-y-optimizaciÃ³n) | âœ… |
| [Redes convolucionales (CNN)](#redes-convolucionales-cnn) | âœ… |
| [Redes recurrentes (RNN)](#redes-recurrentes-rnn) | âœ… |
| [LSTM y GRU](#lstm-y-gru) | âœ… |
| [Sequence to Sequence (Seq2Seq)](#seq2seq) | âœ… |
| [Autoencoders y modelos generativos](#autoencoders-y-modelos-generativos) | âœ… |
| [Mecanismos de atenciÃ³n](#mecanismos-de-atenciÃ³n) | âœ… |
| [Transformers](#transformers) | âœ… |

---

## Neurona de McCulloch-Pitts
**DescripciÃ³n:**  
La primera neurona artificial (1943), un modelo lÃ³gico binario que inspirÃ³ el perceptrÃ³n.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|
|  | [The Mind Project](https://mind.ilstu.edu/curriculum/mcp_neurons/index.html) | *Neural Networks and Learning Machines* (Haykin) | [Ejercicio](ejercicio_mcculloch_pitts.md) |

---

## PerceptrÃ³n
**DescripciÃ³n:**  
Introducido por Frank Rosenblatt en 1958, clasificador lineal base de las redes neuronales.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|
| [video](https://www.youtube.com/watch?v=ntKn5TPHHAk) | [Matt Might â€“ Hello, Perceptron](https://matt.might.net/articles/hello-perceptron/) | *Deep Learning* (Goodfellow) | [Ejercicio](ejercicio_perceptron.md) |

---

## Redes Feedforward (MLP)
**DescripciÃ³n:**  
Redes multicapa donde la informaciÃ³n fluye hacia adelante.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|
| [video](https://www.youtube.com/watch?v=aircAruvnKk) | [DeepLearningBook â€“ Feedforward](https://www.deeplearningbook.org/contents/mlp.html) | *Deep Learning with Python* (Chollet) | [Ejercicio](ejercicio_feedforward_mlp.md) |

---

## Backpropagation
**DescripciÃ³n:**  
Algoritmo de retropropagaciÃ³n que permite entrenar redes profundas ajustando pesos.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|
| [video](https://www.youtube.com/watch?v=tIeHLnjs5U8) | [Neptune.ai â€“ Backpropagation](https://neptune.ai/blog/backpropagation-algorithm-in-neural-networks-guide) | *Neural Networks and Deep Learning* (Nielsen) | [Ejercicio](ejercicio_backpropagation.md) |

---

## Funciones de activaciÃ³n
**DescripciÃ³n:**  
Sigmoid, Tanh, ReLU, LeakyReLU: introducen no linealidad en las redes.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|
| | [GeeksforGeeks â€“ Sigmoid vs ReLU](https://www.geeksforgeeks.org/deep-learning/tanh-vs-sigmoid-vs-relu/) | *Deep Learning* (cap. 6) | [Ejercicio](ejercicio_funciones_activacion.md) |

---

## Redes Radiales (RBF)
**DescripciÃ³n:**  
Redes que clasifican en funciÃ³n de la similitud con prototipos (funciones gaussianas).

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|
| | [Chris McCormick â€“ RBFN Tutorial](https://mccormickml.com/2013/08/15/radial-basis-function-network-rbfn-tutorial/) | *Neural Networks and Learning Machines* | [Ejercicio](ejercicio_rbf.md) |

---

## Redes de Hopfield
**DescripciÃ³n:**  
Modelos de memoria asociativa que almacenan patrones estables.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|
| [video](https://www.youtube.com/watch?v=vaqYWHlnhK8) | [GeeksforGeeks â€“ Hopfield](https://www.geeksforgeeks.org/machine-learning/hopfield-neural-network/) | *Neural Networks and Learning Machines* | [Ejercicio](ejercicio_hopfield.md) |

---

## RegularizaciÃ³n y optimizaciÃ³n
**DescripciÃ³n:**  
TÃ©cnicas como Dropout, BatchNorm y Early Stopping que mejoran la generalizaciÃ³n.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|
| [video](https://www.youtube.com/playlist?list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc) | [MachineLearningMastery â€“ Dropout](https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/) | *Deep Learning* (cap. 7) | [Ejercicio](ejercicio_regularizacion.md) |

---

## Redes convolucionales (CNN)
**DescripciÃ³n:**  
Modelos especializados en imÃ¡genes usando convoluciones y pooling.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|
| [video](https://www.youtube.com/watch?v=iaSUYvmCekI) | [CS231n Notes](https://cs231n.github.io/convolutional-networks/) | *Deep Learning* (cap. 9) | [Ejercicio](ejercicio_cnn.md) |

---

## Redes recurrentes (RNN)
**DescripciÃ³n:**  
Modelos para secuencias, con problemas de gradiente desvanecido.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|
| [video](https://www.youtube.com/watch?v=UNmqTiOnRfg) | [CS230 RNN Cheat Sheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks) | *Deep Learning* (cap. 10) | [Ejercicio](ejercicio_rnn.md) |

---

## LSTM y GRU
**DescripciÃ³n:**  
Variantes de RNN que incorporan compuertas para manejar dependencias largas.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|
| [video](https://www.youtube.com/watch?v=8HyCNIVRbSU) | [GeeksforGeeks â€“ LSTM vs GRU](https://www.geeksforgeeks.org/deep-learning/rnn-vs-lstm-vs-gru-vs-transformers/) | *Deep Learning* | [Ejercicio](ejercicio_lstm_gru.md) |

---

## Seq2Seq
**DescripciÃ³n:**  
Modelos encoder-decoder para traducciÃ³n, resumen y captioning.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|
| [video (conferencia)](https://www.youtube.com/watch?v=6D4EWKJgNn0) | [GeeksforGeeks â€“ Seq2Seq](https://www.geeksforgeeks.org/machine-learning/seq2seq-model-in-machine-learning/) | *Deep Learning* | [Ejercicio](ejercicio_seq2seq.md) |

---

## Autoencoders y modelos generativos
**DescripciÃ³n:**  
Modelos de codificaciÃ³n-decodificaciÃ³n (autoencoders) y generativos (GAN).

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|
| | [GeeksforGeeks â€“ Autoencoders](https://www.geeksforgeeks.org/machine-learning/auto-encoders/) | *Deep Learning* (cap. 14) | [Ejercicio](ejercicio_autoencoders.md) |

---

## Mecanismos de atenciÃ³n
**DescripciÃ³n:**  
Self-attention asigna pesos segÃºn relevancia, clave en NLP moderno.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|
| [video](https://www.youtube.com/watch?v=SysgYptB198) | [DataCamp â€“ Attention](https://www.datacamp.com/blog/attention-mechanism-in-llms-intuition) | *Transformers for NLP* (Rothman) | [Ejercicio](ejercicio_atencion.md) |

---

## Transformers
**DescripciÃ³n:**  
Arquitectura basada en self-attention multi-cabeza y encoder-decoder.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|
| [video](https://www.youtube.com/watch?v=4Bdc55j80l8) | [D2L â€“ Transformers](https://d2l.ai/chapter_attention-mechanisms-and-transformers/transformer.html) | [Attention is All You Need (Vaswani et al., 2017)](https://arxiv.org/abs/1706.03762) | [Ejercicio](ejercicio_transformers.md) |

[Back to top](#deep-learning)

---

[Regresar al menÃº principal](../README.md)
