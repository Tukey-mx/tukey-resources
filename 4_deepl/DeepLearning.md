# Deep Learning
---

âœ… -> AÃ±adido  
âœï¸ -> En progreso

---

## Ãndice

| Tema | Estado |
|------|--------|
| [Neurona de McCullochâ€‘Pitts](#neurona-de-mccullochâ€‘pitts) | âœï¸ |
| [PerceptrÃ³n](#perceptrÃ³n) | âœï¸ |
| [Redes Feedforward (MLP)](#redes-feedforward-mlp) | âœï¸ |
| [Backpropagation](#backpropagation) | âœï¸ |
| [Funciones de activaciÃ³n](#funciones-de-activaciÃ³n) | âœï¸ |
| [Redes Radiales (RBF)](#redes-radiales-rbf) | âœï¸ |
| [Redes de Hopfield](#redes-de-hopfield) | âœï¸ |
| [RegularizaciÃ³n y optimizaciÃ³n](#regularizaciÃ³n-y-optimizaciÃ³n) | âœï¸ |
| [Redes convolucionales (CNN)](#redes-convolucionales-cnn) | âœï¸ |
| [Redes recurrentes (RNN)](#redes-recurrentes-rnn) | âœï¸ |
| [LSTM y GRU](#lstm-y-gru) | âœï¸ |
| [Sequence to Sequence (Seq2Seq)](#seq2seq) | âœï¸ |
| [Autoencoders y modelos generativos](#autoencoders-y-modelos-generativos) | âœï¸ |
| [Mecanismos de atenciÃ³n](#mecanismos-de-atenciÃ³n) | âœï¸ |
| [Transformers](#transformers) | âœï¸ |
---

## Neurona de McCullochâ€‘Pitts

**Objetivos:**
- Comprender la base matemÃ¡tica de la neurona artificial como unidad lÃ³gica.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## PerceptrÃ³n

**Objetivos:**
- Comprender clasificaciÃ³n lineal y limitaciones.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Redes Feedforward (MLP)

**Objetivos:**
- Comprender arquitectura de redes multicapa.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|


---

## Backpropagation

**Objetivos:**
- Entender retropropagaciÃ³n y cÃ¡lculo de gradientes.
- Aprender actualizaciÃ³n de pesos en redes profundas.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Funciones de activaciÃ³n

**Objetivos:**
- Estudiar Sigmoid, Tanh, ReLU, Leaky ReLU, GELU.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Redes Radiales (RBF)

**Objetivos:**
- Comprender redes basadas en funciones gaussianas.
- Evaluar ventajas frente a MLP.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Redes de Hopfield

**Objetivos:**
- Estudiar memoria asociativa y energÃ­a.
- Implementar almacenamiento y recuperaciÃ³n de patrones.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## RegularizaciÃ³n y optimizaciÃ³n

**Objetivos:**
- Dropout, Batch Norm, early stopping.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Redes convolucionales (CNN)

**Objetivos:**
- Estudiar arquitectura de modelos convolucionales.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Redes recurrentes (RNN)

**Objetivos:**
- Comprender modelos secuenciales.
- Estudiar problemas de gradiente.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## LSTM y GRU

**Objetivos:**
- Estudiar el concepto de "compuerta" y observar la ventaja sobre RNNs.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Seq2Seq

**Objetivos:**

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Autoencoders y modelos generativos

**Objetivos:**

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Mecanismos de atenciÃ³n

**Objetivos:**
- Comprender atenciÃ³n y selfâ€‘attention.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Transformers

**Objetivos:**
- Estudiar arquitectura completa: encoder, decoder, heads.

**Recursos:**  
| ğŸ¥ Videos | ğŸ“ ArtÃ­culos | ğŸ“˜ Libros | ğŸ§  Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

[Regresar al menÃº principal](../README.md)