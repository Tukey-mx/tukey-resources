# Deep Learning
---

✅ -> Añadido  
✏️ -> En progreso

---

## Índice

| Tema | Estado |
|------|--------|
| [Neurona de McCulloch‑Pitts](#neurona-de-mcculloch‑pitts) | ✏️ |
| [Perceptrón](#perceptrón) | ✏️ |
| [Redes Feedforward (MLP)](#redes-feedforward-mlp) | ✏️ |
| [Backpropagation](#backpropagation) | ✏️ |
| [Funciones de activación](#funciones-de-activación) | ✏️ |
| [Redes Radiales (RBF)](#redes-radiales-rbf) | ✏️ |
| [Redes de Hopfield](#redes-de-hopfield) | ✏️ |
| [Regularización y optimización](#regularización-y-optimización) | ✏️ |
| [Redes convolucionales (CNN)](#redes-convolucionales-cnn) | ✏️ |
| [Redes recurrentes (RNN)](#redes-recurrentes-rnn) | ✏️ |
| [LSTM y GRU](#lstm-y-gru) | ✏️ |
| [Sequence to Sequence (Seq2Seq)](#seq2seq) | ✏️ |
| [Autoencoders y modelos generativos](#autoencoders-y-modelos-generativos) | ✏️ |
| [Mecanismos de atención](#mecanismos-de-atención) | ✏️ |
| [Transformers](#transformers) | ✏️ |
---

## Neurona de McCulloch‑Pitts

**Objetivos:**
- Comprender la base matemática de la neurona artificial como unidad lógica.

**Recursos:**  
| 🎥 Videos | 📝 Artículos | 📘 Libros | 🧠 Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Perceptrón

**Objetivos:**
- Comprender clasificación lineal y limitaciones.

**Recursos:**  
| 🎥 Videos | 📝 Artículos | 📘 Libros | 🧠 Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Redes Feedforward (MLP)

**Objetivos:**
- Comprender arquitectura de redes multicapa.

**Recursos:**  
| 🎥 Videos | 📝 Artículos | 📘 Libros | 🧠 Ejercicios |
|----------|--------------|-----------|---------------|


---

## Backpropagation

**Objetivos:**
- Entender retropropagación y cálculo de gradientes.
- Aprender actualización de pesos en redes profundas.

**Recursos:**  
| 🎥 Videos | 📝 Artículos | 📘 Libros | 🧠 Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Funciones de activación

**Objetivos:**
- Estudiar Sigmoid, Tanh, ReLU, Leaky ReLU, GELU.

**Recursos:**  
| 🎥 Videos | 📝 Artículos | 📘 Libros | 🧠 Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Redes Radiales (RBF)

**Objetivos:**
- Comprender redes basadas en funciones gaussianas.
- Evaluar ventajas frente a MLP.

**Recursos:**  
| 🎥 Videos | 📝 Artículos | 📘 Libros | 🧠 Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Redes de Hopfield

**Objetivos:**
- Estudiar memoria asociativa y energía.
- Implementar almacenamiento y recuperación de patrones.

**Recursos:**  
| 🎥 Videos | 📝 Artículos | 📘 Libros | 🧠 Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Regularización y optimización

**Objetivos:**
- Dropout, Batch Norm, early stopping.

**Recursos:**  
| 🎥 Videos | 📝 Artículos | 📘 Libros | 🧠 Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Redes convolucionales (CNN)

**Objetivos:**
- Estudiar arquitectura de modelos convolucionales.

**Recursos:**  
| 🎥 Videos | 📝 Artículos | 📘 Libros | 🧠 Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Redes recurrentes (RNN)

**Objetivos:**
- Comprender modelos secuenciales.
- Estudiar problemas de gradiente.

**Recursos:**  
| 🎥 Videos | 📝 Artículos | 📘 Libros | 🧠 Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## LSTM y GRU

**Objetivos:**
- Estudiar el concepto de "compuerta" y observar la ventaja sobre RNNs.

**Recursos:**  
| 🎥 Videos | 📝 Artículos | 📘 Libros | 🧠 Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Seq2Seq

**Objetivos:**

**Recursos:**  
| 🎥 Videos | 📝 Artículos | 📘 Libros | 🧠 Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Autoencoders y modelos generativos

**Objetivos:**

**Recursos:**  
| 🎥 Videos | 📝 Artículos | 📘 Libros | 🧠 Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Mecanismos de atención

**Objetivos:**
- Comprender atención y self‑attention.

**Recursos:**  
| 🎥 Videos | 📝 Artículos | 📘 Libros | 🧠 Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

## Transformers

**Objetivos:**
- Estudiar arquitectura completa: encoder, decoder, heads.

**Recursos:**  
| 🎥 Videos | 📝 Artículos | 📘 Libros | 🧠 Ejercicios |
|----------|--------------|-----------|---------------|

[Back to top](#deep-learning)

---

[Regresar al menú principal](../README.md)