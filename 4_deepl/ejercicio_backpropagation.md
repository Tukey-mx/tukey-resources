# Ejercicio: Backpropagation

## 🎯 Objetivo
Comprender el algoritmo de retropropagación calculando derivadas paso a paso.

---

## 🧩 Instrucciones
1. Considera una red con:
   - 2 entradas
   - 1 capa oculta con 2 neuronas
   - 1 salida
2. Usa activación **sigmoid**.
3. Calcula **manualmente** las derivadas parciales de los pesos:

∂L/∂w = δ * x

4. Implementa una versión en Python que valide tus cálculos.

---

## 🧠 Preguntas
- ¿Qué papel juegan las derivadas en el ajuste de pesos?
- ¿Por qué es importante normalizar las entradas?

---
[Regresar a la página anterior](./DeepLearning.md)

[Regresar al menú principal](../README.md)

