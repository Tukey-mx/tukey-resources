# Ejercicio: Backpropagation

## ğŸ¯ Objetivo
Comprender el algoritmo de retropropagaciÃ³n calculando derivadas paso a paso.

---

## ğŸ§© Instrucciones
1. Considera una red con:
   - 2 entradas
   - 1 capa oculta con 2 neuronas
   - 1 salida
2. Usa activaciÃ³n **sigmoid**.
3. Calcula **manualmente** las derivadas parciales de los pesos:

âˆ‚L/âˆ‚w = Î´ * x

4. Implementa una versiÃ³n en Python que valide tus cÃ¡lculos.

---

## ğŸ§  Preguntas
- Â¿QuÃ© papel juegan las derivadas en el ajuste de pesos?
- Â¿Por quÃ© es importante normalizar las entradas?

---
[Regresar a la pÃ¡gina anterior](./DeepLearning.md)

[Regresar al menÃº principal](../README.md)

